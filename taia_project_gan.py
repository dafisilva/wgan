# -*- coding: utf-8 -*-
"""taia-project-gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O6LJ_9drouxL2ye_Yo8U_Pppod51Wks-

# Imports
"""

import numpy as np
import torch
import torch.nn as nn
import torchvision.models
from torch.utils.data import Dataset,DataLoader
import pandas as pd
import torchvision.transforms as transforms
from sklearn.model_selection import train_test_split
from tqdm import tqdm
from PIL import Image
import copy
import os
import matplotlib.pyplot as plt
import torchvision.datasets
import gc
import random
import torchvision.utils as vutils

"""# Data"""

transform=transforms.Compose([transforms.Resize((64,64)),transforms.ToTensor()])
trainset=torchvision.datasets.CelebA('celeba',split='train',download=True,transform=transform)
trainloader=DataLoader(trainset,batch_size=64,shuffle=True)
print('DATA LOADED SUCCESSFULLY')

"""# Model"""

nz=100
ngf=64
nc=3
ndf=64
# Learning rate for optimizers
lr = 0.002

# Beta1 hyperparam for Adam optimizers
beta1 = 0.5

class Generator(nn.Module):
    def __init__(self, ngpu):
        super(Generator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is Z, going into a convolution
            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # state size. (ngf*8) x 4 x 4
            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # state size. (ngf*4) x 8 x 8
            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # state size. (ngf*2) x 16 x 16
            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # state size. (ngf) x 32 x 32
         
            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),
            nn.Tanh()
            # state size. (nc) x 64 x 64
        )

    def forward(self, input):
        return self.main(input)

class Discriminator(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4

            
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input)

# Discriminator for WGAN
class Discriminator_W(nn.Module):
    def __init__(self, ngpu):
        super(Discriminator_W, self).__init__()
        self.ngpu = ngpu
        self.main = nn.Sequential(
            # input is (nc) x 64 x 64
            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf) x 32 x 32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*2) x 16 x 16
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*4) x 8 x 8
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=True),
            # state size. (ndf*8) x 4 x 4

            
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)
            
        )

    def forward(self, input):
        return self.main(input)



# custom weights initialization called on netG and netD
def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data, 1.0, 0.02)
        nn.init.constant_(m.bias.data, 0)


# custom weights initialization called on netG and netD
def weights_initW(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        nn.init.normal_(m.weight.data, 0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        nn.init.normal_(m.weight.data,0, 0.02)
        nn.init.constant_(m.bias.data, 0)
"""Gradient Penalty"""

def gradient_penalty(critic, real_image, fake_image, device="cuda:0"):
    batch_size, channel, height, width= real_image.shape
    #alpha is selected randomly between 0 and 1
    alpha= torch.rand(batch_size,1,1,1).repeat(1, channel, height, width).to(device)
    # interpolated image=randomly weighted average between a real and fake image
    #interpolated image ← alpha *real image  + (1 − alpha) fake image
    interpolatted_image=(alpha*real_image) + (1-alpha) * fake_image
    
    # calculate the critic score on the interpolated image
    interpolated_score= critic(interpolatted_image)
    
    # take the gradient of the score wrt to the interpolated image
    gradient= torch.autograd.grad(inputs=interpolatted_image,
                                  outputs=interpolated_score,
                                  retain_graph=True,
                                  create_graph=True,
                                  grad_outputs=torch.ones_like(interpolated_score)                          
                                 )[0]
    gradient= gradient.view(gradient.shape[0],-1)
    gradient_norm= gradient.norm(2,dim=1)
    gradient_penalty=torch.mean((gradient_norm-1)**2)
    return gradient_penalty






"""# Training Loop"""

def discriminator_loss(real_img, fake_img):
    real_loss =torch.mean(real_img)
    fake_loss =torch.mean(fake_img)
    return fake_loss - real_loss


def generator_loss(fake_img):
    return -torch.mean(fake_img)    

epochs=200
lambda_gp=10
CRITIC_ITERATIONS = 5
device=torch.device("cuda" if torch.cuda.is_available() else "cpu")

print('\n Instance is running on: ',device)
print('EPOCHS:',epochs)
netG = Generator(1).to(device)
#netG.apply(weights_initW)

netD=Discriminator_W(1).to(device)
#netD.apply(weights_initW)

# Initialize BCELoss function

optimizerG = torch.optim.RMSprop(netG.parameters(), lr=lr)
optimizerD = torch.optim.RMSprop(netD.parameters(), lr=lr)


# Create batch of latent vectors that we will use to visualize
#  the progression of the generator
random.seed(0)
torch.manual_seed(0)

fixed_noise = torch.randn(32, nz, 1, 1, device=device)



epochs=200

min_loss=1e6
save_path='results'
G_losses = []
D_losses = []


for epoch in range(epochs):
    G_loss=0
    D_loss=0
    D_G_z1=0
    D_G_z2=0
    D_x=0
    print(f'\n\nEpoch {epoch+1}/{epochs}:')
    with tqdm(trainloader,unit='batch') as tepoch:
        for data,_ in tepoch:

            ############################
            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))
            ###########################
            ## Train with all-real batch
            
            # Format batch

            # Forward pass real batch through D
            for _ in range(CRITIC_ITERATIONS):
              real_images= data.to(device)
              b_size = real_images.size(0)
 
              netD.zero_grad()

              noise = torch.randn(b_size, nz, 1, 1, device=device)
              # Generate fake image batch with G
              fake_images = netG(noise)
              fake_logits = netD(fake_images.detach()).view(-1)
              real_logits = netD(real_images).view(-1)

              
              gp=gradient_penalty(netD,real_images,fake_images)

              d_loss = -torch.mean(real_logits) + torch.mean(fake_logits) + lambda_gp * gp
              
              d_loss.backward()

              optimizerD.step()

              D_loss+=d_loss.item()/CRITIC_ITERATIONS
            #Train Generator
  
            optimizerG.zero_grad()
            noise = torch.randn(b_size, nz, 1, 1, device=device)

            generated_images=netG(noise)

            gen_img_logits=netD(fake_images.detach()).view(-1)
            # Calculate G's loss based on this output
            g_loss = -torch.mean(gen_img_logits)
            # Calculate gradients for G
            g_loss.backward()


            G_loss+=g_loss.item()
            
            # Update G
            optimizerG.step()
            
            
            
        G_loss=G_loss/len(trainloader)
        D_loss=D_loss/len(trainloader)
        
        
        G_losses.append(G_loss)
        D_losses.append(D_loss)
        
        print(f'D_loss:{D_loss}\nG_loss:{G_loss}')
        
        np.save(os.path.join(save_path,'G_loss'),G_losses)
        np.save(os.path.join(save_path,'D_loss'),D_losses)
        torch.save(netD.state_dict(),os.path.join(save_path,'discriminator.pth'))
        torch.save(netG.state_dict(),os.path.join(save_path,'generator.pth'))
        gc.collect

        fixed_out=netG(fixed_noise)

        
        #final epoch visualization 

        fixed_out=netG(fixed_noise)
        grid=vutils.make_grid(fixed_out,padding=2,normalize=True)

        fig = plt.figure(figsize=(8,8))
        plt.axis("off")

        plt.imshow(np.transpose(grid.detach().cpu().numpy(),(1,2,0)))

        plt.savefig(os.path.join('results/progress_img','epoch'+str(epoch)+'.jpg'))